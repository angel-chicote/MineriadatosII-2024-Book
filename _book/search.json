[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Módulo 8. Minería de Datos II",
    "section": "",
    "text": "Introducción\n\n\n\n\n\n\nFigure 1: Diagrama Conceptual",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "capitulo2.html",
    "href": "capitulo2.html",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "",
    "text": "1.1 Redes Bayesianas\nAl contrario de la Estadística tradicional, el aprendizaje bajo la Estadística Bayesiana tiene un enfoque probabilístico. Así, el razonamiento bayesiano supone que:\nComo veremos más adelante, los modelos bayesianos son muy utilizados en todo tipo de investigaciones debido a que proporcionan muy buenos resultados tanto para problemas descriptivos como predictivos:\nAntes de entrar en detalle en la estructura de los métodos bayesianos definir algunos conceptos:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#redes-bayesianas",
    "href": "capitulo2.html#redes-bayesianas",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "",
    "text": "Las hipótesis están gobernadas por una distribución de probabilidad\nLas decisiones son tomadas de forma “óptima” a partir de las observaciones y dichas probabilidades En este proceso de aprendizaje, las instancias de entrenamiento pueden modificar la probabilidad de una hipótesis, de forma que su planteamiento es mucho menos restrictivo que las técnicas tradicionales (cumplimiento de hipótesis más deterministas). Por tanto, el conocimiento a priori es combinado con las observaciones de los datos con el fin de mejorar el eficiencia de las estimaciones.\n\n\n\nMétodo descriptivo: permite descubrir las relaciones de dependencia/independencia entre las diferentes variables\nMétodo predictivo: son utilizadas como métodos de clasificación. Entre las características de este tipo de técnicas se pueden citar:\nPermite realizar inferencias sobre los datos, lo que conlleva a inducir modelos probabilísticos\nFacilitar la interpretación de otros métodos en términos probabilísticos\nSe necesita conocer un elevado número de probabilidades\nElevado coste computacional al realizar la actualización de las probabilidades\n\n\n\nArco: es un par ordenado (X, Y). En la representación gráfica, un arco (X,Y) viene dado por una flecha desde X hasta Y.\nGrafo dirigido: es un par G = (N, A) donde N es un conjunto de nodos y A un conjunto de arcos definidos sobre los nodos.\nGrafo no dirigido. Es un par G = (N,A) donde N es un conjunto de nodos y A un conjunto de arcos no orientados (es decir, pares noordenados (X,Y)) definidos sobre los nodos. Ciclo: es un camino no dirigido que empieza y termina en el mismo nodo X.\nGrafo acíclico: es un grafo que no contiene ciclos.\nPadre. X es un padre de Y si y sólo si existe un arco X -&gt; Y. Se dice también que Y es hijo de X. Al conjunto de los padres de X se representa como pa(X), y al de los hijos de X por S(X).\nAntepasado o ascendiente. X es un antepasado o ascendiente de Z si y sólo si existe un camino dirigido de X a Z.\nDescendiente. Z es un descendiente de X si y sólo si X es un antepasado de Z. Al conjunto de los descendientes de X lo denotaremos por de(X). - Variable proposicional es una variable aleatoria que toma un conjunto exhaustivo y excluyente de valores. La denotaremos con letras mayúsculas, por ejemplo X, y a un valor cualquiera de la variable con la misma letra en minúscula, x.\nDos variables X e Y son independientes si se tiene que P(X/Y) = P(X). De esta definición se tiene una caracterización de la independencia que se puede utilizar como definición alternativa: X e Y son independientes sí y sólo sí P(X,Y) = P(X)·P(Y).\nDos variables X e Y son independientes dado una tercera variable Z si se tiene que P(X/Y,Z) = P(X/Y). De esta definición se tiene una caracterización de la independencia que se puede utilizar como definición alternativa: X e Y son independientes dado Z sí y sólo sí P(X,Y/Z) = P(X/Z)·P(Y/Z). También se dice que Z separa condicionalmente a X e Y.\n\n\n1.1.1 Modelo Naive Bayes: Hipótesis Map y Teorema de Bayes\nLa inferencia bayesiana es el eje central de los métodos bayesianos. Bajo ella, las hipótesis son expresadas a partir de distribuciones de probabilidad formuladas según los datos observados, \\(p(\\theta)\\), donde \\(\\theta\\) son magnitudes desconocidas. La función verosimilitud, \\(p(y/\\theta)\\), contiene la información disponible en los datos en relación a los parámetros y es ésta la que se usa para actualizar la distribución a priori, \\(p(\\theta)\\)). Finalmente, para llevar a cabo dicha actualización se emplea el Teorema de Bayes.\nPara entender el del Teorema de Bayes es necesario definir los siguientes conceptos:\n\nP(h) es la probabilidad a priori de la hipótesis h. Esta probabilidad contiene la información de que dicha hipótesis sea cierta\nP(D) es la probabilidad a priori de D. Esta es la probabilidad de observar los datos D (sin tener en cuenta la hipótesis que ha de ser cumplida)\nP(h/D) es la probabilidad a posteriori de D, es decir, es la probabilidad de que la hipótesis h una vez los datos D son observados.\nP(D/h) es la probabilidad a posteriori de D, es decir, es la probabilidad de que los datos D sean observados una vez la hipótesis h sea correcta.\n\nSabiendo que la probabilidad conjunta de un evento dado el otro es proporcional a la probabilidad conjunta de ambos ponderada por la probabilidad del evento condicionante, se tiene:\n\\[\nP(h \\cap D) = P(h) \\cdot P(D \\mid h)\n\\]\n\\[\nP(h \\cap D) = P(D) \\cdot P(h \\mid D)\n\\]\nIgualando ambas ecuaciones y manipulando los términos se llega el Teorema de Bayes:\n\\[\nP(h \\mid D) = \\frac{P(h) \\cdot P(D \\mid h)}{P(D)}\n\\]\nDe forma que la probabilidad a posteriori se puede determinar a partir de la probabilidad a priori y un factor de corrección.\nPara una mejora interpretación del Teorema de Bayes se muestra un ejemplo: &gt;En la sala de Pediatría de un determinado hospital el 60% de los pacientes son niñas. De los niños, se conoce que el 35% tienen menos de 24 meses, mientras que para las niñas el 20% son menores de 24 meses. Un médico selecciona una criatura al azar. Si la criatura tiene menos de 24, ¿cuál es la probabilidad de que sea niña? La tabla siguiente muestra la información que se deduce del enunciado:\n\nLa tabla siguiente muestra la información que se deduce del enunciado:\n\n\n\n\nProbabilidad\nValor\n\n\n\n\nP(niño)\n0.40\n\n\nP(niña)\n0.60\n\n\nP(&lt;24m / niño)\n0.35\n\n\nP(&lt;24m / niña)\n0.20\n\n\n\n\nSe obtiene la probabilidad total de que la criatura tenga menos de 24 meses\n\n\\[\nP(&lt;24m) = P(\\text{niño}) \\cdot P(&lt;24m \\mid \\text{niño}) + P(\\text{niña}) \\cdot P(&lt;24m \\mid \\text{niña}) = 0.4 \\cdot 0.35 + 0.6 \\cdot 0.2 = 0.26\n\\]\n\nAplicando el teorema de Bayes:\n\n\\[\nP(\\text{niña} \\mid &lt;24m) = \\frac{P(\\text{niña}) \\cdot P(&lt;24m \\mid \\text{niña})}{P(&lt;24m)} = \\frac{0.6 \\cdot 0.2}{0.26} = 0.46\n\\]\nPor tanto, se tiene un 46% de posibilidades de que el médico haya seleccionado a una niña.\nA partir de la probabilidad a posteriori obtenida mediante la aplicación del Teorema de Bayes, se está en disposición de maximizar tal expresión; es decir, obtener la hipótesis más probable conocida como hipótesis MAP (o máximo a posteriori):\n\\[\nh_{MAP} = \\arg\\max_h P(h \\mid D) = \\arg\\max_h [P(h) \\cdot P(D \\mid h)]\n\\]\nDonde se ha tenido en cuenta que P(D) toma el mismo valor en todas las hipótesis.\n\nSupongamos que estamos tratando de predecir si un estudiante aprueba un examen basándonos en dos características: horas de estudio y nivel de preparación. Nuestras hipótesis son:\n\n\n\n\\(H_1\\): el estudiante aprueba el examen\n\n\n\n\n\\(H_2\\): el estudiante no aprueba el examen\n\n\n\nTenemos los siguientes datos:\n\n\n\n\\(H_1 = 0.7\\): probabilidad de que el estudiante apruebe el examen\n\\(H_2 = 0.3\\): probabilidad de que el estudiante NO apruebe el examen\n\\(P(E\\mid H_1) = 0.8\\): probabilidad de que el estudiante estudie suficiente si aprueba\n\\(P(E\\mid H_2) = 0.8\\): probabilidad de que el estudiante estudie suficiente si NO aprueba\n\n\n\nAhora supongamos que un estudiante estudia durante 4 horas y está muy bien preparado. Queremos calcular las probabilidades a posteriori de que el estudiante apruebe o no apruebe el examen, y determinar la hipótesis MAP.\n\n\n\nCalculamos la probabilidad marginal de observar las evidencias \\(E\\):\n\n\n\\[\nP(E) = P(E \\mid H_1) \\times P(H_1) + P(E \\mid H_2) \\times P(H_2)\n\\]\n\\[\nP(E) = (0.8 \\times 0.7) + (0.3 \\times 0.3) = 0.56 + 0.09 = 0.65\n\\]\n\n\nCalculamos la probabilidad a posteriori de que el estudiante apruebe el examen (\\(H_1\\)) dado que las evidencias \\(E\\) se observan:\n\n\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1) \\times P(H_1)}{P(E)}\n\\]\n\\[\nP(H_1 \\mid E) = \\frac{0.8 \\times 0.7}{0.65} = \\frac{0.56}{0.65} \\approx 0.861\n\\]\n\n\nCalculamos la probabilidad a posteriori de que el estudiante no apruebe el examen (\\(H_2\\)) dado que las evidencias \\(E\\) se observan:\n\n\n\\[\nP(H_2 \\mid E) = \\frac{P(E \\mid H_2) \\times P(H_2)}{P(E)}\n\\]\n\\[\nP(H_2 \\mid E) = \\frac{0.3 \\times 0.3}{0.65} = \\frac{0.09}{0.65} \\approx 0.138\n\\]\n\nPor tanto, la hipótesis más probable es que el estudiante apruebe el examen dado que ha estudiado durante 4 horas y está bien preparado.\n\n\nNota: Dado que \\(P(E)\\) es constante para ambas hipótesis, se podría haber comparado directamente \\(P(H_1 \\mid E)\\) y \\(P(H_2 \\mid E)\\) para determinar la hipótesis MAP.\n\nEl uso de la hipótesis MAP puede ser aplicado para resolver problemas de clasificación.\nComo sabemos, en dichas investigaciones se tiene una variable independiente conocida como clase o target y un conjunto de variables predictoras o atributos. Así, el Teorema de Bayes se puede reescribir como:\n\\[\nP(C \\mid (A_1, A_2, \\ldots, A_N)) = \\frac{P(C) \\cdot P((A_1, A_2, \\ldots, A_N) \\mid C)}{P(A_1, A_2, \\ldots, A_N)}\n\\]\nDonde C denota el target o clase y \\(A_i\\) el conjunto de variables explicativas.\nHaciendo máxima la probabilidad de C dado los atributos se tiene:\n\\[\nc_{MAP} = \\underset{c \\in \\Delta}{\\arg\\max} \\ P(C \\mid (A_1, A_2, \\ldots, A_N)) = P(C) \\cdot P((A_1, A_2, \\ldots, A_N) \\mid C)\n\\]\nsiendo \\(\\Delta\\) el conjunto de valores que puede tomar la variable objetivo (target del problema).\nComo puede verse, el enfoque planteado es bastante sencillo pero también muy costoso desde el punto de vista computacional ya que es necesario conocer las distribuciones de probabilidad de las variables implicadas en la investigación.\n\n\n1.1.2 Modelo Naive-Bayes\nEl clasificador Naïve-Bayes es una versión simplificada del proceso de modelización anterior. Este método supone que todos los atributos son independientes conocido el valor de la variable clase de forma que la función de probabilidad conjunta queda como:\n\n\n\\[P(C \\mid (A_1, A_2, \\ldots, A_N)) = P(C) \\cdot \\prod_{i=1}^{N} P(A_i \\mid C)\\]\n\n\nComo es de esperar, el supuesto que subyace este clasificador no es muy realista; si bien, alcanza muy buenos resultados por lo que su uso está muy extendido en la comunidad de científico de datos.\n\n\n\n\n\n\nFigure 1.1: Naive bayes\n\n\n\nComo en el caso anterior, se obtiene la hipótesis que maximiza la probabilidad del valor de la clase.\n\n\n\\[c_{MAP} = \\underset{c \\in \\Delta}{\\arg\\max} \\left( P(C) \\cdot \\prod_{i=1}^{N} P(A_i \\mid C) \\right)\\]\n\n\nEl clasificador Naïve-Bayes puede emplearse tanto con variables explicativas discretas como numéricas.\nCuando las variables explicativas son discretas, la probabilidad condicional es obtenida a partir de la frecuencia de los datos muestrales; de forma que ésta se define como el número de casos favorables entre el número de casos posibles. Matemáticamente, se tiene:\n\n\n\\[P(x_i \\mid \\text{pa}(x_i)) = \\frac{n(x_i, \\text{pa}(x_i))}{n(\\text{pa}(x_i))}\\]\n\n\nDonde \\(n(x_i, Pa(x_i ))\\) denota el número de registros de la muestra en el que la variable \\(X_i\\) toma el valor \\(x_i\\) y \\(pa(x_i )\\) los padres de \\(X_i\\). Notar que el padre de cada variable explicativa es la variable independiente, la cual se ha denominado target o clase.\nEn el caso en que el tamaño de la muestra de trabajo sea pequeño, el uso de las frecuencias puede ocasionar estimaciones poco fiables por lo que se emplean estimadores basados en suavizados. Uno de los más empleados es el estimador de Laplace en el que la probabilidad viene expresada por el número de casos favorables + 1 dividida por el de casos totales más el número de alternativas.\n\n\n\\[P(x_i \\mid \\text{Pa}(x_i)) = \\frac{n(x_i, \\text{pa}(x_i)) + 1}{n(\\text{pa}(x_i)) + \\alpha}\\]\n\n\nPor su parte, si se dispone de variables numéricas el estimador Naïve-Bayes supone que dichas variables siguen una distribución normal donde la media y la desviación típica son estimadas a partir de los datos de la muestra. Sin embargo, en la mayor parte de las ocasionales, las variables continuas no suelen seguir una distribución de probabilidad normal es posible que las estimaciones sean poco eficientes por lo que se recomienda transformar dichas variables en cualitativas (por ejemplo: empleando los intervalos que se obtienen al tomar los cuantiles de su distribución).\nimport os\nimport numpy as np\nimport pandas as pd\n\ndatos = pd.read_csv(\"../datos/credit_g.csv\")\n\ndatos.info()\n# Pasamos las variables a categóricas\ndatos['checking_status'] = datos['checking_status'].astype('category')\ndatos['credit_history'] = datos['credit_history'].astype('category')\ndatos['purpose'] = datos['purpose'].astype('category')\ndatos['savings_status'] = datos['savings_status'].astype('category')\ndatos['employment'] = datos['employment'].astype('category')\ndatos['personal_status'] = datos['personal_status'].astype('category')\ndatos['other_parties'] = datos['other_parties'].astype('category')\ndatos['property_magnitude'] = datos['property_magnitude'].astype('category')\ndatos['other_payment_plans'] = datos['other_payment_plans'].astype('category')\ndatos['housing'] = datos['housing'].astype('category')\ndatos['job'] = datos['job'].astype('category')\ndatos['property_magnitude'] = datos['property_magnitude'].astype('category')\ndatos['own_telephone'] = datos['own_telephone'].astype('category')\ndatos['foreign_worker'] = datos['foreign_worker'].astype('category')\ndatos['class'] = datos['class'].astype('category')\n# La variable class es una variable reservada en diferentes módulos de Python -&gt; reemplazar por por target\ndatos.rename(columns={'class': 'target'}, inplace=True)\ndatos['target']=np.where(datos['target']=='good', 0, 1) # cambio en la codificación por sencillez en el preprocesado\n# Definición de la muestra de trabajo\ndatos_entrada = datos.drop('target', axis=1) # Datos de entrada\ndatos_entrada = pd.get_dummies(datos_entrada, drop_first=True, dtype=int) #conversión a variables dummy\n\ntarget = datos[\"target\"] # muestra del target\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n\n# Partición de la muestra\n\ntest_size = 0.3 # muestra para el test \nseed = 222 # semilla\n\nX_train, X_test, y_train, y_test = train_test_split(\n    datos_entrada, target, test_size=test_size, random_state=seed, stratify=target\n)\n\n# Estandarización de la muestra\nesc = StandardScaler().fit(X_train) # valores media y std de los datos de train\n\n# aplicación a los datos de train y test\nX_train_esc = esc.transform(X_train)\nX_test_esc = esc.transform(X_test)\n\n# Validación cruczada\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=seed)\n\n1.1.2.1 Bernoulli Naive Bayes\nfrom sklearn.naive_bayes import BernoulliNB \nbernoulli_nb=BernoulliNB(force_alpha=False)\n\ngrid=[{'alpha': list(np.arange(0.05, 1, 0.1)), 'binarize': [0.3, 0.1, 0.0]}]\n# Definición del modelo con hiperparámetros\ngs_bernoulli_nb = GridSearchCV(\n    estimator=bernoulli_nb, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=1, return_train_score=False\n)\ngs_bernoulli_nb = gs_bernoulli_nb.fit(X_train, y_train)\n\nprint(f'Naive-Bayes (Bernoulli) (parámetros): {gs_bernoulli_nb.best_params_}') # parámetros del modelo final\n\nbernoulli_nb = gs_bernoulli_nb.best_estimator_ # modelo final\n# Resultados importantes de estos algoritmos (acceso dentro del objeto del modelo)\nprint(bernoulli_nb.class_log_prior_)  # logaritmo de la probabilidad de cada clase\nprint(bernoulli_nb.class_log_prior_)  # logaritmo de la probabilidad de cada clase\nbernoulli_nb.feature_log_prob_ # logaritmo de la probabilidad de la variable dada la clase (P(Xi|Y)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n\nimport warnings\n# Suprimir todas las advertencias\nwarnings.simplefilter(\"ignore\")\n\n\n# Predicciones muestra entrenamiento y test\n\npreds_train = bernoulli_nb.predict(X_train)\npreds_test = bernoulli_nb.predict(X_test)\n\n# Cálculo métricas bondad de ajuste \nprint('Accuracy')\nprint('------------------------------')\nprint(f'Entrenamiento (cv): {round(gs_bernoulli_nb.best_score_,5)}')\naccuracy_test = accuracy_score(y_test, preds_test)\nprint(f'Test: {round(accuracy_test,5)}')\n\n# AUC - test y curva roc (final\ny_pred_test = bernoulli_nb.predict_proba(X_test)\nfp_rate_test, tp_rate_test, thresholds = roc_curve(y_test, y_pred_test[:,1])\nauc_test = auc(fp_rate_test, tp_rate_test)\n\n# Bondad de ajuste: matriz de confusión y curva roc para los datos de test\n\nf, axes = plt.subplots(1, 2, figsize=(10,5))\n\nsns.heatmap(confusion_matrix(preds_test, y_test), annot = True, cmap = plt.cm.Reds, fmt='.0f', ax=axes[0]) # matriz de confusión\nsns.lineplot(x=fp_rate_test, y=tp_rate_test, color='skyblue', label='AUC = %0.2f' % auc_test, ax=axes[1]) # curva roc\n\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n1.1.2.2 Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB  \n\ngaussian_nb = GaussianNB()\ngrid=[{'var_smoothing': list(np.arange(0,0.1, 0.02))}]\n\n# Definición del modelo con hiperparámetros\ngs_gaussian_nb=GridSearchCV(\n    estimator=gaussian_nb, param_grid=grid, scoring='accuracy', cv=cv, n_jobs=1, return_train_score=False\n)\n\ngs_gaussian_nb = gs_gaussian_nb.fit(X_train, y_train)\nprint('Naive-Bayes (Bernoulli) (parámetros):', gs_gaussian_nb.best_params_) \n\n#parámetros del modelo final\ngaussian_nb = gs_gaussian_nb.best_estimator_ #modelo final\n\n# predicciones muestra entrenamiento y test\n\npreds_train = gaussian_nb.predict(X_train)\npreds_test = gaussian_nb.predict(X_test)\n\n# Cálculo métricas bondad de ajuste \n\nprint('Accuracy')\nprint('------------------------------')\nprint(f'Entrenamiento (cv):, {round(gs_gaussian_nb.best_score_,5)}')\naccuracy_test = accuracy_score(y_test, preds_test)\nprint('Test:', round(accuracy_test,5))\n\n#AUC - test y curva roc (final)\n\ny_pred_test = gaussian_nb.predict_proba(X_test)\nfp_rate_test, tp_rate_test, thresholds = roc_curve(y_test, y_pred_test[:,1])\nauc_test = auc(fp_rate_test, tp_rate_test)\n\n# Bondad de ajuste: matriz de confusión y curva roc para los datos de test\n\nf, axes = plt.subplots(1, 2, figsize=(10,5))\n\nsns.heatmap(confusion_matrix(preds_test, y_test), annot = True, cmap = plt.cm.Reds, fmt='.0f', ax=axes[0]) # matriz de confusión\nsns.lineplot(x=fp_rate_test, y=tp_rate_test, color='skyblue', label='AUC = %0.2f' % auc_test, ax=axes[1]) # curva roc\n\nplt.legend(loc=\"lower right\")\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#modelos-bayesianos",
    "href": "capitulo2.html#modelos-bayesianos",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "1.2 Modelos Bayesianos",
    "text": "1.2 Modelos Bayesianos\nLas redes bayesianas son métodos estadísticos que representan la incertidumbre a través de las relaciones de independencia condicional que se establecen entre ellas. Por tanto, permiten modelar un fenómeno a partir de dichas relaciones y hacer inferencia.\nEste tipo de métodos son una representación gráfica de dependencias para razonamiento probabilístico, en las que los nodos representan variables aleatorias y los arcos las relaciones de dependencia directa entre las variables.\n\n\n\n\n\n\nFigure 1.2: Topologia Bayesiana\n\n\n\nLa ventaja de las redes bayesianas frente a otros métodos es la posibilidad de codificar las dependencias/independencias relevantes considerando no sólo las dependencias marginales sino también las dependencias condicionales entre un conjunto de variables.\nEn definitiva, las redes bayesianas modelan las relaciones entre las variables tanto de forma cualitativa como cuantitativa. La fuerza de dichas relaciones viene dada en las distribuciones de probabilidad como una medida de la creencia que tenemos sobre esas relaciones en el modelo.\n\n1.2.1 Formulación general\nUna red bayesiana queda especificada formalmente por una dupla B=(G,Θ) donde G es un grafo dirigido acíclico (DAG, por las siglas en inglés) y Θ es el conjunto de distribuciones de probabilidad. Definimos un grafo como un par G = (V, E), donde V es un conjunto finito de vértices, nodos o variables, y E es un subconjunto del producto cartesiano VxV de pares ordenados de nodos que llamamos enlaces o aristas. Por tanto, puede decirse que las redes bayesianas representan el conocimiento cualitativo del modelo mediante el grafo dirigido acíclico.\n\nSupongamos una red bayesiana que contine un padre A y 3 hijos (B, C y D), siendo C también padre de B. El DAG que definido sería:\n\nimport bnlearn as bn\nimport matplotlib.pyplot as plt\n\nedges = [('A', 'B'), ('A', 'C'), ('A', 'D'), ('C', 'B')]\nDAG = bn.make_DAG(edges, methodtype=\"bayes\")\n\nbn.plot(DAG, interactive=False)\nplt.show()\n\n# print(DAG[\"adjmat\"])  # podemos ver el dag en formato tabla (no visual cuando existen muchos nodos)\nEl grafo define un modelo probabilístico mediante el producto de varias funciones de probabilidad condicionada:\n\n\n\\[P(x_1, \\ldots, x_n) = \\prod_{i=1}^{N} P(x_i \\mid \\text{pa}(x_i))\\]\n\n\nCon \\(pa(x_i)\\) las variables inmediatamente predecesoras de la variable \\(X_i\\). En este sentido, los valores de probabilidades \\(P(x_i⁄pa(x_i ))\\) son “almacenados” en el nodo que precede a la variable \\(X_i\\).\nEs importante resaltar que de no existir la expresión anterior, la red debiese ser descrita a partir de la probabilidad conjunta, lo que obligaría a trabajar con un número de parámetros mucho más elevado (creciente de forma exponencial en el número de nodos).\n\n\n1.2.2 Independencia condicional e inferencia de la red\nComo se ha comentado anteriormente, una variable X es condicionalmente independiente de otra variable Y dada una tercera Z si, el hecho de que se tenga conocimiento Z, hace que Y no tenga influencia en X.\n\n\n\\[P(X|Y,Z)=P(X|Z)\\]\n\n\nPor tanto, la hipótesis de independencia condicional establece que cada nodo debe ser independiente de los otros nodos de la red (salvo sus descendientes) dados sus padres. Dicho de otro modo, si se conocen los padres de una variable, ésta se vuelve independiente del resto de sus predecesores.\n\nVeamos un ejemplo para facilitar la comprensión de la independencia condicional.\n\n\n\n\n\n\n\nFigure 1.3: Topologia Bayesiana\n\n\n\n\nPartiendo de la red bayesiana de la imagen anterior, la probabilidad conjunta se define como:\n\n\\[\\begin{align}\nP(X_1, X_2, \\ldots, X_9) &= P(X_1) \\cdot P(X_2) \\cdot P(X_3 \\mid X_2, X_1) \\cdot P(X_4 \\mid X_3, X_2, X_1) \\\\\n&\\quad \\cdot P(X_5 \\mid X_4, X_3, X_2, X_1) \\cdot P(X_6 \\mid X_5, X_4, X_3, X_2, X_1) \\\\\n&\\quad \\cdot P(X_7 \\mid X_6, X_5, X_4, X_3, X_2, X_1) \\\\\n&\\quad \\cdot P(X_8 \\mid X_7, X_6, X_5, X_4, X_3, X_2, X_1) \\\\\n&\\quad \\cdot P(X_9 \\mid X_8, X_7, X_6, X_5, X_4, X_3, X_2, X_1)\n\\end{align}\\]\n\nEn cambio, como las probabilidades condicionales solo dependen de sus padres (teorema anterior), la probabilidad conjunta toma la siguiente forma:\n\n\\[\\begin{align}\nP(X_1, X_2, \\ldots, X_9) &= P(X_1) \\cdot P(X_2) \\cdot P(X_3 \\mid X_2) \\cdot P(X_4 \\mid X_2, X_1) \\\\\n&\\quad \\cdot P(X_5 \\mid X_4) \\cdot P(X_6 \\mid X_4) \\cdot P(X_7 \\mid X_4) \\\\\n&\\quad \\cdot P(X_8 \\mid X_3) \\cdot P(X_9 \\mid X_3)\n\\end{align}\\]\nPor tanto, *la propiedad de independencia de las redes bayesianas hace que se reduzca en gran medida los cálculos**.\nEn una red bayesiana, se conoce como inferencia probabilística a la propagación del conocimiento a través de la misma una vez se tienen nuevos datos. Este proceso se lleva a cabo actualizando las probabilidades a posteriori en toda la estructura de la red mediante el Teorema de Bayes.\nComo es de imaginar, el proceso de inferencia es muy costoso computacionalmente de forma que, dependiendo de las necesidades, se emplean algoritmos exactos o aproximados:\n\nExactos: cuando puede calcularse la inferencia de forma exacta. El coste computacional necesario para la actualización de las probabilidades es viable\nAproximados: se usan técnicas de muestreo que permita calcular de forma aproximada la inferencia. Usado cuando no es viable obtener la propagación exacta en un tiempo razonable\n\n\n\n1.2.3 Aprendizaje de las redes bayesianas\nComo se ha visto, para determinar una red bayesiana es necesario especificar su estructura gráfica y una función de probabilidad conjunta. Dicho proceso es bastante laborioso debido a que, en muchos casos, se desconoce ambas especificaciones. Para paliar esta circunstancia, se han desarrollado diferentes métodos de aprendizaje. Así, el proceso de aprendizaje de una red bayesiana puede dividirse en dos estapas:\n\nEstructural (o dimensión cualitativa): búsqueda en el espacio de posibles redes\nParamétrico (o dimensión cuantitativa): aprende la distribución de probabilidad a partir de los datos, dada la red\n\nEl aprendizaje paramétrico consiste en hallar los parámetros asociados a la estructura de la red. Estos parámetros están constituidos por las probabilidades de los nodos raíz y las probabilidades condicionales de las demás variables dados sus padres. Las probabilidades previas se corresponden con las marginales de los nodos raíz y las condicionales se obtienen de las distribuciones de cada nodo con sus padres.\nEn el aprendizaje estructural es donde se establecen las relaciones de dependencia que existen entre las variables del conjunto de datos para obtener el mejor grafo que represente estas relaciones. Este problema se hace prácticamente intratable desde el punto de vista computacional cuando el número de variables es grande. Por ello, suelen emplearse algoritmos de búsqueda para aprender la estructura de la red.\nA continuación, se presentan algunos algoritmos de búsqueda para establecer la estructura de una red bayesiana.\nAlgoritmo K2\nEl algoritmo K2 es considerado el predecesor de otros algoritmos de búsqueda más sofisticados. basado en búsqueda y optimización de una métrica bayesiana es considerado como el predecesor y fuente de inspiración para las generaciones posteriores. El proceso de búsqueda de este algoritmo está dividido en las siguientes etapas: - Ordenación de los nodos (variables de entrada) de forma que los posibles padres de una variable aparezcan siempre antes de ella para evitar la generación de ciclos. Esta restricción provoca que el algoritmo busque los padres posibles entre las variables predecesoras (ventaja computacional) - Partiendo de este orden establecido, se calcula la ganancia que se produce en la medida al introducir una variable como padre\nFinalmente, el proceso se repite para cada nodo mientras el incremento de calidad supere un cierto umbral preestablecido.\nAlgoritmo B\nEste algoritmo elimina la dependencia de la ordenación previa de los nodos de forma que su coste de computación es superior al algoritmo K2. complejidad computacional es mayor. Como en el caso anterior, el proceso es iniciado con padres vacíos con padres vacíos y en cada etapa se añade aquel enlace que maximice el incremento de calidad eliminando aquellos que producen ciclos. El proceso es detenido cuando una vez la inclusión de un arco no represente ninguna ganancia.\nAlgoritmo Hill Climbing\nEl algoritmo Hill Climbing (HC) es un procedimiento de búsqueda que parte de una solución inicial y, a partir de ésta, mediante técnicas heurística se calcula el nuevo valor utilizando todas las soluciones vecinas a la solución actual, seleccionando el vecino que mejor solución presenta. Por tanto, este algoritmo finaliza cuando no existe ningún vecino que pueda mejorar la solución vecina.\nUna variante muy útil y muy empleada consiste en considerar todos los posibles movimientos a partir del estado actual y elegir el mejor de ellos como nuevo estado. A este método se le denomina ascensión por la máxima pendiente o búsqueda del gradiente.\n\nVamos a mostrar un ejemplo de aprendizaje de la estructura en python:\n\nimport pandas as pd\n\ndatos = pd.read_csv(\"../datos/bayesian_data.csv\", sep=\";\", index_col=\"Unnamed: 0\")\ndatos = datos.rename(columns={'class': 'target'})  # target con 4 categorías\n\n\n# Modelo de estructura\nstructure_model = bn.structure_learning.fit(datos, methodtype='tan', root_node=\"doors\", class_node=\"target\") # uso de hill-climbing\n\n# nota: en este caso no estamos definiendo un padre para obtener la estructura bayesian\nstructure_model[\"adjmat\"]\nimport matplotlib.pyplot as plt\nbn.plot(model)\nplt.show()\n\nTanto del cuadro como del grafo, podemos ver que:\n\n\n\ntarget es padre de: safety, lug_boot y person\ntarget es hijo de: buying y maint\n\n\n\n\n1.2.4 Clasificadores\nComo determinar la estructura de la red bayesiana es una tarea realmente compleja, la mayor parte de los modelos de clasificación basados en redes bayesianas suelen ser modificaciones del clasificador Naïve-Bayes.\nA día de hoy, existen muchos clasificadores de forma que se exponen brevemente tres de los más utilizados.\nTan: Tree Augmented Naïve Bayes\nEn el modelo TAN todos los atributos tienen como padre a otro atributo como mucho, además de la clase en sí, de forma que cada atributo obtiene un arco aumentado apuntando a él. \nBan: Naïve Bayes aumentado\nEn este modelo se incorporan nuevos arcos entre todas las variables con la limitación de que no formen ciclos. Destacar la relevancia de este clasificador ya que su estructura es capaz de representar cualquier forma de red bayesiana. \nAODE: Average One-Dependence Estimators\nAl igual que el algoritmo TAN, cada variable tiene como padre a la variable clase y como máximo a otro atributo. Sin embargo, la principal diferencia respecto al modelo anterior tiene lugar en la forma de obtener la predicción definitiva del modelo. Dicha predicción consiste en: - El algoritmo establece posibles estructuras de red compatibles con el problema y, en función de ésta, hace una predicción de la clase - La predicción final se obtiene como la media ponderada de las predicciones anteriores \nUna vez visto la parte teórica entramos en detalle a nivel práctico.\nstructure_tan_model = bn.structure_learning.fit(\n    datos,\n    methodtype='tan',\n    root_node=\"doors\", # hay que tener en cuenta algún hijo que no tenga más padre que el target\n    class_node=\"target\"  # en el modelo tan hay que tener una clase/padre)\n) \nparameter_model = bn.parameter_learning.fit(structure_tan_model, datos, methodtype='bayes', verbose=0) \nstructure_tan_model[\"model_edges\"] # bordes y nodos. También podría pintarse como en el caso anterior\n\nObención de las probabilidades condicionadas\n\n# Probabilidades condicionadas\n\nCPDs = bn.print_CPD(parameter_model, verbose=0)  # esto es un diccionario de dataframes (clave cada columna del df\n- Para doors:\nCPDs[\"doors\"][CPDs[\"doors\"][\"target\"] == 0]\n- Para maint (y primera clase del target):\nCPDs[\"maint\"][CPDs[\"maint\"][\"target\"] == 0]\nObtención de las Predicciones sobre la muestra\nfeats = list(datos.columns)\nfeats.remove(\"target\")\n\n# dado las evidencias de dos variables, calculamos la probabilidad de la clase\nquery = bn.inference.fit(parameter_model, variables=[\"target\"], evidence={'doors':2, 'lug_boot': 'small'}, verbose=0)\n\nquery.df\nPor último, presentamos un ejemplo de uso de clasificador bayesiano empleando la librería pyAgrum. Esta librería es que es un contenedor de Python para la biblioteca aGrUM de C++. Proporciona una interfaz de alto nivel a la parte de aGrUM que permite crear, modelar, aprender, usar, calcular e integrar redes bayesianas y otros modelos gráficos probabilísticos como las redes de Markov o los modelos relacionales probabilísticos.\nLa librería se integra adecuadamente con scikit-learn por lo que se recomienda su uso para desarrollar clasificadores bayesianos.\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nimport pyAgrum.skbn as skbn\nimport pyAgrum.lib.notebook as gnb\n\ndatos = pd.read_csv(\"../datos/credit_g.csv\")\n\ndatos.info()\n# Pasamos las variables a categóricas\ndatos['checking_status'] = datos['checking_status'].astype('category')\ndatos['credit_history'] = datos['credit_history'].astype('category')\ndatos['purpose'] = datos['purpose'].astype('category')\ndatos['savings_status'] = datos['savings_status'].astype('category')\ndatos['employment'] = datos['employment'].astype('category')\ndatos['personal_status'] = datos['personal_status'].astype('category')\ndatos['other_parties'] = datos['other_parties'].astype('category')\ndatos['property_magnitude'] = datos['property_magnitude'].astype('category')\ndatos['other_payment_plans'] = datos['other_payment_plans'].astype('category')\ndatos['housing'] = datos['housing'].astype('category')\ndatos['job'] = datos['job'].astype('category')\ndatos['property_magnitude'] = datos['property_magnitude'].astype('category')\ndatos['own_telephone'] = datos['own_telephone'].astype('category')\ndatos['foreign_worker'] = datos['foreign_worker'].astype('category')\ndatos['class'] = datos['class'].astype('category')\n\n# La variable class es una variable reservada en diferentes módulos de Python -&gt; reemplazar por por target\ndatos.rename(columns={'class': 'target'}, inplace=True)\ndatos['target']=np.where(datos['target']=='good', 0, 1) # cambio en la codificación por sencillez en el preprocesado\n\n# Definición de la muestra de trabajo\ndatos_entrada = datos.drop('target', axis=1) # Datos de entrada\ndatos_entrada = pd.get_dummies(datos_entrada, drop_first=True, dtype=int) #conversión a variables dummy\n\ntarget = datos[\"target\"] # muestra del target\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n\n# Partición de la muestra\n\ntest_size = 0.3 # muestra para el test \nseed = 222 # semilla\n\nX_train, X_test, y_train, y_test = train_test_split(\n    datos_entrada, target, test_size=test_size, random_state=seed, stratify=target\n)\n\n# Estandarización de la muestra\nesc = StandardScaler().fit(X_train) # valores media y std de los datos de train\n\n# aplicación a los datos de train y test\nX_train_esc = esc.transform(X_train)\nX_test_esc = esc.transform(X_test)\n# Creación del clasificador TAN en python\nbayesian_network = skbn.BNClassifier(\n    learningMethod='TAN',\n    prior='Smoothing',\n    scoringType='BIC',\n    priorWeight=0.5,\n    discretizationStrategy='quantile',\n    usePR=True,\n    significant_digit = 6\n)\n\nbayesian_network.fit(X_train, y_train) # ajuste del modelo\nfrom sklearn.metrics import accuracy_score\n\n# predicciones para la muestra de train y test\n\ntrain_probs = bn.predict_proba(X_train)  \ntest_probs = bn.predict_proba(X_test)\n\n# predict-proba proporciona las probabilidades\n\ndef preds_ones(probs, threshold = 0.5):\n    return np.where(probs[:, 0] &gt; threshold, 0, 1)\n\ny_train_pred = preds_ones(train_probs)\ny_test_pred = preds_ones(tests_probs)\n\nprint(f'Accuracy (train) {round(accuracy_score(y_train, y_train_pred),2)}')\nprint(f'Accuracy (test) {round(accuracy_score(y_test, y_test_pred), 2)}')",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#modelos-ocultos-de-markov",
    "href": "capitulo2.html#modelos-ocultos-de-markov",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "1.3 Modelos Ocultos de Markov",
    "text": "1.3 Modelos Ocultos de Markov\n\n1.3.1 Cadenas de Markov\nUna cadena de Markov es un sistema matemático que experimenta transiciones de un estado a otro de acuerdo con un conjunto dado de reglas probabilísticas. La siguiente imagen presenta una representación gráfica de una cadena de Markov.\n\n\n\n\n\n\nFigure 1.4: Cadena Markow\n\n\n\nComo puede verse, una cadena de Markov puede ser planteada como un gráfico dirigido en el que los nodos son los estados y los arcos contienen la probabilidad de pasar de un estado a otro.\nLas cadenas de Markov son procesos estocásticos pero se diferencian en que carecen de memoria. Así, en un proceso de Markov la probabilidad del siguiente estado del sistema depende solamente del estado actual del sistema y no de ningún estado anterior.\n\n\\[P(x_i│x_0 … x_{i-1})= P(x_i│x_{i-1})\\]\n\nLa expresión anterior se conoce como propiedad de Markov.\nEs importante destacar que una cadena de Markov puede ser vista como una red bayesiana en la que cada nodo tiene una tabla de probabilidad correspondiente a \\(P(x_t│x_{t-1})\\) y es a misma para todos los nodos salvo para el instante inicial.\n\n\n\n\n\n\nFigure 1.5: Cadena Markov\n\n\n\nEn toda cadena de Markov es necesario definir una matriz de transición, T, la cual contiene la información sobre la probabilidad de transición entre los diferentes estados del sistema. Como hecho relevante, cada fila de la matriz debe ser un vector de probabilidad y la suma de todos sus términos debe ser igual a la unidad.\nAsimismo, las matrices de transición tienen la propiedad de que el producto de las matrices posteriores puede describir las probabilidades de transición a lo largo de un intervalo de tiempo. Esta característica permite modelar la probabilidad de estar en un determinado estado después de n pasos como:\n\n\\[p^n= p^0* T^n\\]\n\nVeamos un ejemplo con el que facilitar la comprensión del funcionamiento de una cadena de Markov.\n\nUn grupo farmacéutico ha sacado al mercado tres pomadas hace pocas semanas. Con el fin de conocer su acogida así como el comportamiento futuro de los potenciales clientes ante las tres variantes del producto ha realizado un estudio de mercado. De dicho estudio se conocen las probabilidades de cambio de un tipo de pomada a otra.\n\n\nLa matriz de transición para T es:\n\n\n\n\n\\[\nT = \\begin{pmatrix}\n0.80 & 0.10 & 0.10 \\\\\n0.03 & 0.95 & 0.02 \\\\\n0.20 & 0.05 & 0.75 \\\\\n\\end{pmatrix}\n\\]\n\n\n\n\nSabiendo que actualmente, la participación en el mercado de las tres pomadas es:\n\n\n\n\n\\[\np = \\begin{pmatrix}\n0.30 \\\\\n0.45 \\\\\n0.25 \\\\\n\\end{pmatrix}\n\\]\n\n\n\n\n¿Cuáles serán las participaciones de mercado de cada marca en dos meses más?\n\n\nLa matriz de transición para \\(T^2\\) es:\n\n\n\n\n\\[\nT^2 = \\begin{pmatrix}\n0.663 & 0.180 & 0.155 \\\\\n0.057 & 0.907 & 0.037 \\\\\n0.312 & 0.105 & 0.584 \\\\\n\\end{pmatrix}\n\\]\n\n\n\n\nDe forma que usando la fórmula anterior, se tiene:\n\n\n\n\n\\[\np^2 = p^0 \\cdot T^2 = \\begin{pmatrix}\n0.30 & 0.45 & 0.25\n\\end{pmatrix} \\begin{pmatrix}\n0.663 & 0.180 & 0.155 \\\\\n0.057 & 0.907 & 0.037 \\\\\n0.312 & 0.105 & 0.584 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n0.302 & 0.488 & 0.209\n\\end{pmatrix}\n\\]\n\n\n\n\nEn vista de los resultados, la cuota de mercado de cada tipo de pomada variará en los dos meses siguientes en: - Pomada 1: de un 30% a 30,2% (estable) - Pomada 2: de un 45% a un 48,8% (leve aumento) - Pomada 3: de un 25% a un 20,9% (ligera caída)\n\n\n\n1.3.2 Cadena de Markov absorvente\nUna cadena de Markov absorbente es una cadena de Markov en la que para algunos estados una vez ingresados, no es posible salir. Sin embargo, este es solo uno de los requisitos previos para que una cadena de Markov sea una cadena de Markov absorbente. Para que sea una cadena de Markov absorbente, todos los demás estados transitorios deben poder alcanzar el estado absorbente con una probabilidad de 1.\nCon el fin de ayudar al entendimiento del comportamiento de una cadena de Markov arbsorvente, se plantea una simulación en python sobre la calidad creditia de n individuos y su comportamiento durante un año (12 pagos).\nSuponiendo un modelo de impago bancario con los siguientes tres estados: - Pago al día - Pago con retraso - Impago (estado absorbente)\nAsí, la matriz de transición para esta cadena de Markov es:\n\n\n\\[\nT = \\begin{pmatrix}\n0.8 & 0.1 & 0.0 \\\\\n0.2 & 0.4 & 0.4 \\\\\n0.0 & 0.0 & 1.0 \\\\\n\\end{pmatrix}\n\\]\n\n\nEsto significa que hay un 80% de probabilidad de que un individuo que paga al día continúe pagando al día, un 20% de probabilidad de que pase a un estado de pago con retraso, y un 0% de probabilidad de que entre en estado de impago (para pasar a impago debe pasar previamente por pago con retraso). Además, hay un 20% de probabilidad de que un individuo en estado de pago con retraso vuelva al estado de pago al día, un 40% de probabilidad de que permanezca en estado de pago con retraso y un 20% de probabilidad de que entre en estado de impago. Por último, el estado de impago es absorbente, lo que significa que una vez que un individuo entra en estado de impago, permanece allí indefinidamente.\nimport numpy as np\n\nnp.random.seed(123)\n\n# Matriz de transición completa\ntransition_matrix = np.array([[0.8, 0.2, 0.0],  # De pago al día a pago con retraso o impago\n                              [0.45, 0.4, 0.15],  # De pago con retraso a pago al día o impago\n                              [0.0, 0.0, 1.0]]) # De impago a impago (estado de absorción)\n\n# Muestra de individuos + número de pagos\nn_samples = 10\nn_pagos = 12\n\ny = np.zeros(n_samples, dtype=int)  # Todos los individuos comienzan en estado de pago al día\n\nmuestra_dict = {} # Diccionario para recoger los pagos de cada muestra\nfor i in range(n_samples):\n    # Generar transiciones de estado basadas en la matriz de transición completa\n    current_state = 0  # Estado inicial: pago al día\n    pagos_muestra_list = [] # Obtener secuencia en cada mes de pago\n    for _ in range(n_pagos):  # Realizar los 12 pagos\n        if current_state == 0:  # Si estamos en el estado de pago al día\n            # solo nos quedamos con las posibles transiciones (no es posible ir al impago sin tener retraso en pago)\n            next_state = np.random.choice([0, 1], p=transition_matrix[current_state][0:2])\n        elif current_state == 1:  # Si estamos en el estado de pago con retraso\n            # una vez estamos en retraso pago podemos volver a regular pagos (pago al día) o ir a impoago\n            next_state = np.random.choice([0, 1, 2], p=transition_matrix[current_state])\n        else:  # Si estamos en el estado de impago\n            y[i] = 1  # estado absorbente\n            break\n        current_state = next_state\n        pagos_muestra_list.append(current_state)\n        muestra_dict[f\"Individuo_{i}\"] = pagos_muestra_list\nEn el diccionario muestra_dict se ha guardado el comportamiento de cada individuo a lo largo de los 12 pagos posteriores al punto inicial.\nmuestra_dict\nComo puede verse, la mayor parte de individuos no llegan al estado de impago y esto es consecuencia de las probabilidades existentes en la matriz de transición de partida.\nLa secuencia de pagos del Individuo_5 hace que sea de interés focalizarse en él para detallar el impacto que tienen las cadenas de markov. Como puede verse, al inicio de pago se empieza a retrasar hasta volver a regularizar sus pagos a mediados del segundo trimestre. Tras esta regularización, meses después vuelve a caer de estado.\nLas cadenas de Markov absorbentes tienen algunas propiedades específicas que las diferencian de las cadenas de Markov más simples. La más destacada es la referida a la forma en que la matriz de transición puede ser escrita. Sea una cadena con t estados transitorios y r estados absorbentes, la matriz de transición T puede escribirse en su forma canónica como:\n\n\n\\[\nT = \\begin{pmatrix}\nQ & R \\\\\n0 & I_t \\\\\n\\end{pmatrix}\n\\]\n\n\nDonde Q es una matriz de txt, R es una matriz de txr, 0 es una matriz de ceros de rxt e It es la matriz identidad de txt.\nEn particular, la descomposición de la matriz de transición en la matriz fundamental permite ciertos cálculos, como el número esperado de pasos hasta la absorción de cada estado. La matriz fundamental N se calcula de la siguiente manera:\n\n\n\\[\nN= (I_t-Q)^{-1}\n\\]\n\n\nSiendo I_t es la matriz identidad de txt. Así, para obtener el número esperado de pasos se calcula como:\n\n\n\\[\nn= N*1\n\\]\n\n\nDonde 1 denota un vector columna de valor uno y longitud igual al número estados transitorios.\nPor último, la probabilidad de que un estado transitorio sea absorbido es calculada como:\n\n\n\\[\np_{trans \\rightarrow abs}= N * R\n\\]\n\n\nVeamos un ejemplo de Cadena de Markov absorbente con el que podamos ver en detalle estos cálculos matriciales:\n\nImaginemos un cliente en un casino. Por cada apuesta gana 1€ con probabilidad de 0.3 o pierde 1€ con probabilidad de 0.7. Sabiendo que la apuesta ha sido iniciada con 2 € y que el cliente se retirará se retirará si pierde todo el dinero o bien lo duplica. Se pide:\n\n\nCuestión 1: Escribir la matriz de transición de una cadena de Markov\nCuestión 2: Determinar el promedio de apuestas hasta que el juego termina\nCuestión 3: Determinar la probabilidad de terminar el juego con 4€ o de marcharse de vacío\n\n\nCuestión 1: Del enunciado se conoce que se tienen 5 posibles estados (0, 1, 2, 3, 4) siendo los estados 0 y 4 absorbentes (pierde todo o duplica la apuesta, respectivamente). Teniendo en cuenta los posibles movimientos y las probabilidades asociadas se tiene:\n\n\n\\[\nT = \\begin{pmatrix}\nt_{00} & t_{01} & t_{02} & t_{03} & t_{04} \\\\\nt_{10} & t_{11} & t_{12} & t_{13} & t_{14} \\\\\nt_{20} & t_{21} & t_{22} & t_{23} & t_{24} \\\\\nt_{30} & t_{31} & t_{32} & t_{33} & t_{34} \\\\\nt_{40} & t_{41} & t_{42} & t_{43} & t_{44} \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n0.7 & 0 & 0.3 & 0 & 0 \\\\\n0 & 0.7 & 0 & 0.3 & 0 \\\\\n0 & 0 & 0.7 & 0 & 0.3 \\\\\n0 & 0 & 0 & 0 & 1 \\\\\n\\end{pmatrix}\n\\]\n\n\n\n\nCuestión 2: Se escribe la matriz T en su forma canónica. Notar que para ello es necesario reorganizar los estados (ahora, los estados absorbentes están en las últimas filas de la matriz T).\n\n\n\\[\nT =\n\\begin{pmatrix}\nQ & R \\\\\n0 & I_t \\\\\n\\end{pmatrix}\n= \\begin{pmatrix}\nt_{11} & t_{12} & t_{13} & t_{10} & t_{14} \\\\\nt_{21} & t_{22} & t_{23} & t_{20} & t_{24} \\\\\nt_{31} & t_{32} & t_{33} & t_{30} & t_{34} \\\\\nt_{01} & t_{02} & t_{03} & t_{00} & t_{04} \\\\\nt_{41} & t_{42} & t_{43} & t_{40} & t_{44} \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n0 & 0.3 & 0 & 0.7 & 0 \\\\\n0.7 & 0 & 0.3 & 0 & 0 \\\\\n0 & 0.7 & 0 & 0 & 0.3 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 \\\\\n\\end{pmatrix}\n\\]\n\n\n\n\nDe forma que Q y R son:\n\n\n\\[ Q = \\begin{pmatrix} 0.0 & 0.3 & 0.0 \\\\ 0.7 & 0.0 & 0.3 \\\\ 0.0 & 0.7 & 0.0 \\end{pmatrix}  \\] \\[ R = \\begin{pmatrix} 0.7 & 0.0 \\\\ 0.0 & 0.0 \\\\ 0.0 & 0.3 \\end{pmatrix} \\]\n\n\n\n\nEl número de apuestas hasta terminar el juego es:\n\n\n\n\n\\[\nN= (I_t-Q)^{-1} * 1 = {\\begin{pmatrix} 0.0 & 0.3 & 0.0 \\\\ 0.7 & 0.0 & 0.3 \\\\ 0.0 & 0.7 & 0.0 \\end{pmatrix}}^{-1} *\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} =\n\\begin{pmatrix} 1.362 & 0.517 & 0.155 \\\\ 1.207 & 1.724 & 0.517 \\\\ 0.845 &  1.207 & 1.362 \\end{pmatrix} *\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2.034 \\\\ 3.448 \\\\ 3.414 \\end{pmatrix}\n\\]\n\n\n\n\nTeniendo en cuenta que el cliente empezó su apuesta con 2€, el número de apuestas esperadas hasta que el juego acabe son 3.448€.\n\n\nCuestión 3: En este caso, se sabe que la probabilidad de llegar a un estado absorbente desde uno transitorio sigue la siguiente expresión:\n\n\n\\[\np_{trans \\rightarrow abs}= N * R = (I_t-Q)^{-1} * R =\n\\begin{pmatrix} 1.362 & 0.517 & 0.155 \\\\ 1.207 & 1.724 & 0.517 \\\\ 0.845 &  1.207 & 1.362 \\end{pmatrix} *\n\\begin{pmatrix} 0.7 & 0\\\\ 0 & 0 \\\\ 0 & 0.3 \\end{pmatrix} = \\begin{pmatrix} 0.953 & 0.046 \\\\ 0.845 & 0.155\\\\ 0.591 & 0.409 \\end{pmatrix}\n\\]\n\n\n\n\nAsí, la probabilidad de que el cliente acabe con 4€ es de 15.5%. Por su parte, se tiene un 84.5% de posibilidades de que se vaya de vacío.\n\n\n\n1.3.3 Modelos Ocultos de Markov\nLos Modelos Ocultos de Markov, HMMs (por sus siglas en inglés) son una extensión de las cadenas de Markov y sirven para tratar tanto eventos observables (presentes en la cadena de entrada) como eventos ocultos que consideramos causales del modelo probabilístico. Los Modelos Ocultos de Markov son utilizados cuando se conocen las evidencias sobre un sistema pero no los estados tienen lugar de forma que buscan establecer la relación existente entre los estados visibles y los ocultos. Algunos ejemplos de uso de este tipo de modelos:\n\nSeparación de secuencias de nucleótidos por sus características biológicas (exón-intrón)\nRelacionar proteínas con sus funcionalidades\nLocalización de genes en las células eucariotas\nReconocimiento del habla\nEtiquetado de texto y traducción automática\n\nEn un HMM, para cada instante de tiempo o posición t en una secuencia se tiene:\n\nUna variable aleatoria \\(X_t\\), con posibles estados \\(s_1, … ,s_n\\) (no observables directamente)\nOtra variable aleatoria \\(E_t\\), con posibles estados \\(v_1, … ,v_m\\) (observaciones)\n\nPara un buen funcionamiento de este tipo de modelos se asume dos propiedades:\n\nPropiedad de Markov: en cada posición, el estado solo depende del estado en la posición inmediatamente anterior: \\(P(X_t│Y, X_{t-1}) = P(X_t│X_{t-1})\\)\nIndpendencia de las observaciones: en cada posición, la observación solo depende del estado en esa posición: \\(P(E_t│Y, X_t )=P(E_t│X_t)\\)\n\nDe forma análoga a las cadenas de Markov, un HMM también puede ser expresado según una red bayesiana:\n\n\n\n\n\n\nFigure 1.6: HMM\n\n\n\nAsí, cada nodo \\(X_t\\) la misma tabla de probabilidad correspondiente a \\(P(X_t│X_{t-1})\\) salvo en el instante anterior. Por el contrario, cada nodo \\(E_t\\) tiene una única tabla de probabilidad correspondiente a \\(P(E_t│X_t)\\).\nAdemás de los estados ocultos y observables comentados anteriormente, un Modelo Oculto de Markov consta también de otros elementos que son citados a continuación:\n\nRespecto a los estados ocultos:\n\nLa matriz de probabilidades entre los estados, A, denominada matriz de transición. Así, \\(a_{ij}=P(X_t=s_j│X_{t-1}=s_i)\\) es la probabilidad de pasar del estado si al estado \\(s_j\\) Es importante destacar que el modelo probabilístico que describe la manera de transitar entre una posición y la siguiente no cambia a lo largo de la secuencia.\nEl vector de probabilidades a priori de cada estado, \\(\\pi\\), con \\(\\pi_i=P(x_1=s_i)\\) - Respecto a las observaciones: - La matriz de probabilidades de los observables, B, conocida como matriz de observación. Así, \\(b_{ij}=P(E_t=v_j│X_t=s_i)\\) es la probabilidad de observar \\(v_j\\) cuando el estado es \\(s_i\\)\n\n\nEs importante destacar que el modelo probabilístico que describe la emisión de la observación en cada estado no cambia a lo largo de la secuencia.\nPor tanto, un HMM está formado por la combinación de dos tipos de modelos: - El transicional el cual responde a los estados ocultos - El modelo de evidencias que tiene en cuenta la información disponible de las observaciones\nUn ejemplo básico sobre el uso de Modelos Ocultos de Markov en bioinformática se plantea a continuación. En este ejemplo, se parte de una secuencia de ADN ficticia (observaciones) y se hace uso de un HHM para predecir la probabilidad de los estados ocultos (“codificación de genes” y “regiones no codificantes”) en la secuencia de ADN.\nimport numpy as np\nfrom hmmlearn import hmm\n\nnp.random.seed(444)\n\ndna_sequence = \"TCGAATCGAAGTATCGGCATTGGCTCGAGCGATCGATGCTAGCA\"\nstates = [\"Gene\", \"Non-Gene\"]\n\n# Conversión de la secuencia de ADN a números para que el modelo HMM pueda procesarla\n# Por ejemplo, A=0, C=1, G=2, T=3\ndna_encoded = np.array([[0 if base == \"A\" else 1 if base == \"C\" else 2 if base == \"G\" else 3 for base in dna_sequence]]).T\n# Definir y entrenar el modelo\nmodel = hmm.CategoricalHMM(n_components=2, n_iter=100) # las componentes son los estados\nmodel.fit(dna_encoded) \nmodel.predict_proba(dna_encoded)[0:20] # probabilidades de decodificación\n# Decodificar los estados ocultos (genes vs no genes) utilizando el modelo entrenado\ndecoded_states = model.predict(dna_encoded) # predict asume un threshold de 0.5\n\n# Decodificar los estados ocultos a sus etiquetas originales\ndecoded_states_labels = [states[state] for state in decoded_states]\n\nprint(f\"Secuencia de ADN: {dna_sequence}\")\nprint(f\"Estados ocultos predichos: {decoded_states_labels}\")\nDado una secuencia de observaciones \\(o_1 o_2 … o_t\\), mediante un Modelo Oculto de Markov se pueden responder a distintos tipos de problemas como: - Filtrado: permite conocer la probabilidad de que \\(X_t=q\\) - Explicación más verosímil: también conocida como decodificación, permite conocer la secuencia de estados más probable.\nA continuación, se presenta un ejemplo para explicar en detalle el proceso de obtención del filtrado y de la explicación más verosímil en un Modelo Oculto de Markov.\nSuponga un trabajador en una plataforma de petróleo que no tiene contacto con el exterior en todo un año. Debido a su profesión, desconoce la situación meteorológica de cada día (si llueve o no), pero todas las mañanas siempre ve llegar al gerente a su oficina. El gerente unos días viene con paraguas y otros no. Imagine entonces que un sistema formado por dos estados ocultos (lluvia, no lluvia) y dos observaciones (paraguas, no paraguas) es utilizado para pronosticar el tiempo por el trabajador. La siguiente imagen muestra la estructura de un Modelo Oculto de Markov en formato de red.\n\n\n\n\n\n\nFigure 1.7: Ejemplo HHM\n\n\n\nEl ejemplo es detallado tanto siguiendo los cálculos “manualmente” como a partir de una implementación en python.\nLos vectors de información a priori como las matrices de probabilidad entre estados y las matrices de probablidad de observables se obtienen directamente del enunciado:\nimport numpy as np\n\n# Definir parámetros del modelo HMM como listas y diccionarios\n\nstates = ('lluvia', 'no_lluvia')\nobservations = ('paraguas', 'no_paraguas')\n\nstart_probability = {'lluvia': 0.5, 'no_lluvia': 0.5} # Vector de información a priori\n\n# Matrices de probabilidad entre estados \ntransition_probability = {\n    'lluvia': {'lluvia': 0.7, 'no_lluvia': 0.3},\n    'no_lluvia': {'lluvia': 0.3, 'no_lluvia': 0.7},\n}\n\n# Matriz de probabilidad de observables \nemission_probability = {\n    'lluvia': {'paraguas': 0.9, 'no_paraguas': 0.1},\n    'no_lluvia': {'paraguas': 0.2, 'no_paraguas': 0.8},\n}\n\n1.3.3.1 Filtrado\n\n1.3.3.1.1 Implementación del Algoritmo Forward\nSe define la función para calcular la probabilidad conjunta de una secuencia de observaciones y estados usando el algoritmo de avance (forward).\ndef forward(obs, states, start_p, trans_p, emit_p):\n    alpha = np.zeros((len(obs), len(states)))\n\n    # Inicializar primer paso\n    for i, state in enumerate(states):\n        alpha[0][i] = start_p[state] * emit_p[state][obs[0]]\n\n    # Recorrer el resto de la secuencia de observaciones\n    for t in range(1, len(obs)):\n        for i, current_state in enumerate(states):\n            alpha[t][i] = sum(alpha[t-1][j] * trans_p[states[j]][current_state] * emit_p[current_state][obs[t]] for j in range(len(states)))\n\n    return alpha\n# Secuencia de observaciones y estados de los tres primeros días\nobservations_sequence = ['paraguas', 'paraguas', 'no_paraguas']\n\n# Calcula la probabilidad conjunta de la secuencia de observaciones y estados usando el algoritmo de avance\nalpha = forward(observations_sequence, states, start_probability, transition_probability, emission_probability)\nalpha\n# Suma de las probabilidades en el último paso para obtener la probabilidad total de la secuencia de observaciones\nprobability_sequence = np.sum(alpha[-1])\nalpha[-1] / probability_sequence # Probabilidad normalizada en el último paso (día 3)\nAsí, la probabilidad de que el día 3 sea lluvia es del 19%\n\n\n\n1.3.3.2 Explicación más verosimil\n\n1.3.3.2.1 Implementación del algoritmo Viterbi\nFunción para calcular la secuencia de estados más probable utilizando el algoritmo Viterbi\ndef viterbi(obs, states, start_p, trans_p, emit_p):\n    V = [{}]\n    path = {}\n\n    # Inicializar primer paso\n    for state in states:\n        V[0][state] = start_p[state] * emit_p[state][obs[0]]\n        path[state] = [state]\n\n    # Recorrer el resto de la secuencia de observaciones\n    for t in range(1, len(obs)):\n        V.append({})\n        new_path = {}\n\n        for current_state in states:\n            (prob, state) = max(\n                (V[t - 1][previous_state] * trans_p[previous_state][current_state] * emit_p[current_state][obs[t]], previous_state)\n                for previous_state in states\n            )\n            V[t][current_state] = prob\n            new_path[current_state] = path[state] + [current_state]\n\n        path = new_path\n\n    # Encontrar el estado final con la mayor probabilidad\n    (prob, state) = max((V[len(obs) - 1][final_state], final_state) for final_state in states)\n\n    return (prob, path[state])\nSe aplica la función y se obtiene tanto la secuencia de estados ocultosmás probable como la probabilidad de ésta.\nprob, path = viterbi(observations_sequence, states, start_probability, transition_probability, emission_probability)\nprint(f\"Secuencia de estados ocultos más probable: {path}\")\nprint(f\"Probabilidad de la secuencia más probable: {prob}\")\n\n\n\n1.3.3.3 Aplicación de un HMM: Post-tagging\nEl post-tagging es una tarea fundamental en el procesamiento del lenguaje natural (NLP por sus siglas en inglés) que consiste en asignar etiquetas gramaticales a cada palabra en una oración después de haber sido segmentada en palabras individuales. Esta tarea es crucial para comprender el significado y la estructura de las oraciones, ya que las etiquetas gramaticales proporcionan información sobre la función sintáctica de cada palabra.\nEn el contexto del post-tagging, los estados del HMM representan las etiquetas gramaticales de las palabras, las transiciones representan la dependencia entre las etiquetas gramaticales de las palabras consecutivas y las emisiones representan la probabilidad de que una palabra dada se observe en un estado determinado.\nPara realizar el post-tagging con un HMM, se sigue el siguiente procedimiento:\n\nEntrenamiento del modelo: se entrena con un conjunto de datos de oraciones etiquetadas, aprendiendo las probabilidades de transición y emisión\nPredicción de etiquetas: para una nueva oración sin etiquetar, el modelo predice la secuencia de etiquetas gramaticales más probable para la oración, utilizando el algoritmo de Viterbi\n\nVentajas\n\nFlexibilidad: pueden modelar secuencias de palabras con diferentes patrones gramaticales\n\nInterpretabilidad: Los estados del HMM pueden interpretarse como diferentes tipos de palabras o estructuras gramaticales.\nRobustez: Los HMMs son robustos a errores de segmentación de palabras y a palabras desconocidas.\nLimitaciones\n\nDependencia de datos: el rendimiento del modelo depende de la calidad y cantidad de datos de entrenamiento disponibles\nAmbigüedad gramatical: pueden no ser capaces de resolver ambigüedades gramaticales en oraciones complejas\nNecesidad de preprocesamiento: requiere preprocesamiento previo de las oraciones, como la segmentación de palabras.\n\nimport warnings\n\nimport nltk\nimport numpy as np\nfrom hmmlearn import hmm\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom nltk.corpus import brown # corpus con etiquetado\n\n# Cargar las sentencias etiquetadas del corpus brown\ntagged_sentences = brown.tagged_sents(tagset='english')\n\n# Crear un diccionario de palabras y un diccionario de etiquetas\nword2idx = {}\ntag2idx = {}\n\n# Iterar sobre las sentencias etiquetadas para construir los diccionarios\nfor sentence in tagged_sentences:\n    for word, tag in sentence:\n        if word.lower() not in word2idx:\n            word2idx[word.lower()] = len(word2idx)\n        if tag not in tag2idx:\n            tag2idx[tag] = len(tag2idx)\n\n# Estos diccionarios serán útiles para convertir palabras y tags en índices numéricos que nuestro modelo HMM pueda entender.\n\n# Conjunto de entrenamiento\nwords_train = [] # Lista de palabras (en minúscualas por lower)  \ntags_train = [] # Lista de etiquetas\nfor sentence in tagged_sentences:\n    words, tags = zip(*sentence)\n    words_train.append([word.lower() for word in words])\n    tags_train.append(tags)\n# Creación y entrenamiento del modelo HMM\nmodel = hmm.MultinomialHMM(n_components=len(tag2idx), init_params=\"ste\") # estados ocultos como número de etiquetas\nmodel.fit(\n    X=np.array([word2idx[word] for words in words_train for word in words]).reshape(-1, 1),\n    lengths=[len(words) for words in words_train]\n) # El entrenamiento se hace converiendo a índices las palabras\n# Función para realizar post-tagging en una nueva sentencia en castellano\ndef post_tag(model, sentence, word2idx, tag2idx):\n    \n    # Convertir las palabras de la sentencia a índices\n    word_idxs = [word2idx[word.lower()] for word in sentence if word.lower() in word2idx]\n    \n    # Si no hay palabras conocidas, devolver None\n    if len(word_idxs) == 0:\n        return None\n    \n    # Realizar post-tagging utilizando el modelo HMM\n    predicted_tags = model.predict(np.array(word_idxs).reshape(-1, 1))\n    \n    # Convertir los índices de etiquetas a etiquetas POS\n    predicted_tags = [list(tag2idx.keys())[list(tag2idx.values()).index(tag)] for tag in predicted_tags]\n    \n    return list(zip(sentence, predicted_tags))\nsentence = \"I love Python\"\npredicted_tags = post_tag(model, sentence.split(), word2idx, tag2idx)\nprint(f\"Post-tagging de la oración: {predicted_tags}\")\n# Librerias necesarias\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\n\nfrom graphviz import Source\nfrom scipy.stats import norm\nfrom sklearn.mixture import GaussianMixture\nfrom graphviz import Digraph\nfrom IPython.display import display\n\n\nfrom xgboost import XGBRegressor, XGBClassifier\nimport seaborn as sns\n\n# from causalml.inference.meta import XGBTLearner, MLPTLearner\nfrom causalml.inference.meta import BaseSRegressor, BaseTRegressor, BaseXRegressor, BaseRRegressor\nfrom causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\nfrom causalml.inference.meta import LRSRegressor\nfrom causalml.match import NearestNeighborMatch, MatchOptimizer, create_table_one\nfrom causalml.propensity import ElasticNetPropensityModel\nfrom causalml.dataset import *\nfrom causalml.metrics import *\n\n\n# imports from package\nimport logging\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\nimport statsmodels.api as sm\nfrom copy import deepcopy",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#correlación-no-implica-causalidad",
    "href": "capitulo2.html#correlación-no-implica-causalidad",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "2.1 Correlación no implica causalidad",
    "text": "2.1 Correlación no implica causalidad\n\n\n\nxkcd: correlación\n\n\nA menudo se suelen confundir la causalidad con la correlación, lo que nos puede llevar a un gran error. Si entramos a este famoso sitio web podremos disfrutar rápidamente de algunos gráficos muy cómicos, que parecen sugerir una relación fáctica entre variables realmente diferentes. Por ejemplo, este gráfico muestra simultáneamente la cantidad anual de bebes que fueron llamados como Stevie versus la cotización de Amazon:\n\n\n\nRelaciones\n\n\nEstos ejemplos de correlaciones espurias nos muestran que dos variables pueden aparecer asociadas, incluso cuando lo más plausible es que no tengan absolutamente nada que ver.\nTambién es muy conocida la Docena del Datasaurio, creada por Albert Cairo:\n\n\n\nDocena del Datasaurio\n\n\nEstos conjuntos de datos sintéticos tienen la peculiaridad de tener los mismos valores de los principales estadísticos sumarios: promedios, desviaciones estándar y el coeficiente de correlación de Pearson.\nEstos ejemplos se usan típicamente para enfatizar la importancia de visualizar nuestros datos antes de realizar análisis. También sirven para enfatizar que la correlación presente en los datos puede ser altamente no lineal, por lo cual una medida como la correlación de Pearson, que mide correlación lineal, puede resultar engañosa.\nDetrás de todas estas nociones de correlación hay un concepto fundamental, que es el de la dependencia probabilística. Dadas dos variables aleatorias \\(X, Y\\), decimos que son probabilísticamente independientes si su distribución de probabilidad conjunta se factoriza como \\(p(X, Y) = p(X) p(Y)\\). Equivalentemente, condicionar sobre una de las dos variables no afecta la distribución de valores de la otra:\n\\[ p(X | Y=y) = p(X) \\] \\[ p(Y | X=x) = p(Y) \\]\nVamos a usar una notación especial para esta situación de independencia entre \\(X\\) e \\(Y\\):\n\\[\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp} X \\indep Y\\]\nTambién usaremos el concepto de independencia condicional: \\(X\\) es independiente de \\(Y\\) dado \\(Z\\) (escribimos \\(X \\perp \\!\\!\\! \\perp Y | Z\\)) si \\(p(X, Y | Z) = p(X | Z) p(Y | Z)\\).\nEsta dependencia probabilistica nos permite definir correlación de una manera formal. Diremos que dos variables \\(X\\), \\(Y\\) están correlacionadas en alguna medida siempre que \\(p(X, Y) \\neq p(X) p(Y)\\).\nEn el fondo, todo análisis de inferencia estadística asume que nuestros datos son muestras extraídas de una distribución de probabilidad conjunta \\(p(X_1, X_2, \\dots)\\) (donde las \\(X_i\\) son nuestras variables aleatorias). Esta distribución de probabilidad viene a ser nuestro modelo del “mundo real”, y nuestro objetivo será estimar, a través de los datos, ciertas características de esa distribución. Para poder pasar de inferencia estadística a inferencia causal, es indispensable añadir una nueva capa de modelización, que codifica explícitamente nuestras hipótesis sobre las relaciones causales entre las variables presentes.\nHemos dicho que correlación no implica causalidad, pero por el contrario, si veo correlación, es más probable que haya causalidad que si no observo nada. De hecho el filósofo Hans Reichenbach formuló a mediados del Siglo XX el Principio de la Causa Común, según el cual dadas dos variables correlacionadas, o bien una es causa de la otra, o bien al revés, o bien ambas tienen una causa común. Es decir que la correlación es nuestra herramienta para detectar causalidad, y lo que debemos hacer es poder identificar cuándo correlación sí implica causalidad.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#los-mundos-contrafácticos",
    "href": "capitulo2.html#los-mundos-contrafácticos",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "2.2 Los mundos contrafácticos",
    "text": "2.2 Los mundos contrafácticos\nUna forma de entender la causalidad tiene que ver con entender preguntas del tipo “¿Qué habría pasado si…?”, que son el ejemplo más paradigmático del pensamiento contrafáctico. Muchas veces se dice que no tiene sentido preguntarse por contrafácticos, dado que es imposible saber lo que habría pasado. En verdad, esto no es del todo correcto: es verdad que en la amplia mayoría de las situaciones no tenemos herramientas para saber con certeza qué habría pasado, pero cada vez que hacemos una afirmación causal del estilo “salí con paraguas porque estaba lloviendo”, estamos afirmando que tenemos confianza sobre qué habríamos hecho si no hubiera estado lloviendo y todos los demás aspectos del mundo se hubieran mantenido constantes (en particular, confiamos en que no habríamos salido con paraguas en tal caso).\n\n2.2.1 Causalidad en un mundo ideal\nVeamos un ejemplo para aclarar:\nSupongamos que tras una herida grave, y estamos pensando si ir o no al hospital. Queremos saber si una visita al hospital tendrá un efecto positivo sobre nuestra salud.\nLa pregunta es: ¿lo que sucede si voy al hospital será mejor a lo que sucede si no voy al hospital?. Queremos comparar los resultado obtenidos tras ir / no ir al hospital. Pero claro, para comparar entre dos resultados, debemos poder observarlos. En la vida real, está claro que si tomas una opción, no has podido tomar la otra, pero en nuestro caso, imaginemos por un momento que podemos observar ambos escenarios.\nDefiniremos la variable aleatoria aleatoria \\(Y_i\\) como un indicador de salud. Esta variable puede variar en función de si vamos o no vamos al hospital, es decir, en función del tratamiento, que llamaremos \\(T_i\\):\n\nTratamiento del individuo \\(i\\)\n\n\\[\n    T_i=\n    \\begin{cases}\n      1 & \\text{si fue al hospital} \\\\\n      0 & \\text{si no fue al hospital}\n    \\end{cases}\n\\]\n\nResultado observado para el individuo \\(i\\)\n\n\\[ Y_i= \\text{indicador de salud} \\]\n\nResultados potenciales para el individuo i\n\n\\[   Y_i(T_i) =\n    \\begin{cases}\n      Y_i(1)  & \\text{resultado potencial de ir al hospital} \\\\\n      Y_i(0)  & \\text{resultado potencial de no ir al hospital}\n    \\end{cases}\n\\]\nUna vez hemos observado el valor de la variable \\(Y_i\\) tras ir (y tras no ir) al hospital, podemos definir el efecto individual de tratamiento (ITE) como la diferencia en el resultado de salud cuando vamos al hospital y el resultado de salud cuando no vamos al hospital:\n\\[\nITE_{i} =  \\underbrace{Y_{i}(T_{i} = 1)}_{\\substack{\\text{ Resultado observado} \\\\ \\text{tras ir al hospital}}}\n- \\underbrace{Y_{i}(T_{i} = 0)}_{\\substack{\\text{ Resultado observado} \\\\ \\text{tras NO ir al hospital}}} = Y(1) - Y(0)\n\\]\nSi podemos observar realizaciones de las variables aleatorias \\(Y\\), \\(T\\) y calcular el \\(ITE\\) para ellas, podremos estimar la distribución del \\(ITE\\), o algunos de sus momentos, como la media o la varianza. En particular, a la media de los ITE la llamamos efecto medio de tratamiento (ATE, por Average Treatment Effect).\n\\[\nATE = \\mathbb{E}[ITE]\n\\]\nNOTA:: para hacer esta comparación, debemos mantener constante todo el resto de las circunstancias. Necesitamos una dimensión paralela, donde lo único que cambia es el hecho de ir o no ir al hospital. Si cambiasemos alguna otra variable, y luego observamos otro resultado, no podemos asegurarnos de que haya sido el hecho de ir al hospital y no el de otra variable el responsable del resultado que observamos.\nDado el ejemplo, parece facil estimar el efecto de un tratamiento, pero recordemos que en la vida real sólo un resultado potencial se realiza. O vamos al hospital (\\(T_i = 1\\)), o no vamos (\\(T_i = 0\\)). Para una misma persona, bajo las exactas mismas circunstancias, sólo tendremos un resultado observado, por lo tanto, no podremos acceder al ITE, y en consecuencia, tampoco podemos calcular el ATE. ¡Nos faltan datos!\n\n\n2.2.2 Mecanismo de comparación\nImaginemos que tenemos una muestra de \\(N\\) individuos. Para cada individuo en una circunstancia dada, observamos una realización de la variable aleatoria \\(Y_i\\) (el estado de salud) y una realización de la variable \\(T_i\\) (si fue o no fue al hospital).\n\nIdealmente, querríamos ver el ATE, pero como solo podemos ver un caso para cada individuo, esto es imposible.\nDebemos cambiar un poco nuestra pregunta, tratar de aproximarnos al ATE de otra manera. Si tenemos \\(N\\) individuos donde algunos fueron al hospital y otros no, ¿por qué no comparamos la salud promedio entre quienes fueron y quienes no fueron al hospital?\n\n\nLos siguientes datos están tomados de Angrist y Pischke (2008)\n\nLos datos de la National Health Interview Survey (NHIS) de Estados Unidos tienen dos preguntas que podemos usar como muestras de nuestras variables de interés: 1. Durante los últimos 12 meses, ¿el encuestado pasó una noche en el hospital? \\(\\rightarrow T_i\\) 2. ¿Diría que su salud es excelente, muy buena, buena, regular o mala? \\(\\rightarrow Y_i\\) (asignando 1 a “excelente” y 5 a “mala”)\nComparemos los dos resultados observados con los que contamos. Calculemos la salud promedio para los que fueron al hospital, y para quienes no fueron, y calculemos la diferencia.\n\n\n\n\n\n\n\n\n\n\\(T_i\\) (grupo)\n\\(N\\) (tamaño de muestra)\n\\(\\widehat{E[Y_i \\mid T=t]}\\) (salud promedio del grupo)\nDesvío est.\n\n\n\n\n1 (fue al hospital)\n7774\n2.79\n0.014\n\n\n0 (no fue al hospital)\n90049\n2.07\n0.003\n\n\n\nEn este caso tenemos:\n\\[\n  \\underbrace{\\widehat{\\mathbb{E}[Y_i | T_i=1]}}_{\\substack{\\text{ Salud (resultado observado) promedio} \\\\ \\text{en los que fueron al hospital}}}  - \\underbrace{\\widehat{\\mathbb{E}[Y_i | T = 0]}}_{\\substack{\\text{Salud (resultado observado) promedio} \\\\ \\text{en los que  NO fueron al hospital}}}  = \\quad 2.79 - 2.07 \\quad = \\quad \\underbrace{0.72}_{\\substack{\\text{Diferencia promedio} \\\\ \\text{en el indicador de mala salud}}}\n\\]\nEn promedio, la salud de los que fueron al hospital es ¡peor! que la salud de los que no fueron al hospital… ¿qué es lo que puede estar pasando?¿Podemos decir que ir al hospital causa un peor estado de salud?\nProbablemente, lo que sucede es que la condición de salud previa de las personas que pasan una noche en el hospital es peor que la de aquellos que no fueron. Es posible que haber ido al hospital haya mejorado el estado de salud de la persona, pero no lo suficiente como para que su estado de salud sea igual o mejor a aquellos que no tuvieron que ir al hospital porque estaban sanos.\nEntonces, “ir al hospital” está reflejando no solamente la atención médica recibida en el hospital, sino también la condición de salud previa que hizo que esas personas fueran al hospital.\nGráficamente, sería algo así:\n\n#Especificamos engine='neato' para poder usar argumento `pos` en nodos\ndot = Digraph(engine='neato')\ndot.node('T', 'Hospital', pos='1,1!')\ndot.node('Y', 'Estado de salud', pos='3,1!')\ndot.node('X', 'Condición de salud previa', pos='2,2!')\ndot.edges(['TY', 'XY', 'XT'])\ndot\n\n\n2.2.3 Confusores y sesgos\nDecimos que la “condición de salud previa” es un confusor: Una variable que está correlacionada tanto con el tratamiento \\(T_i\\) (ir al hospital) como con el resultado \\(Y_i\\) (el estado de salud posterior). Si no tomamos en cuenta este confusor, confundimos el efecto de la visita al hospital con el confusor. Decimos que cuando comparamos la salud promedio observada entre quienes fueron al hospital y quienes no, además del efecto causal de la visita al hospital, tenemos un sesgo de selección: las personas que “se autoseleccionan” para ir a hospital son distintas de las que no van.\nComparar al grupo de personas que va al hospital con el grupo de personas que no va no sirve para responder nuestra pregunta contrafáctica: ¿una persona que sí fue, está mejor que si no hubiera ido?. Dado que no estamos cumpliendo con la comparación ceteris paribus: las circunstancias de un grupo (condición mala de salud previa), no son iguales a las del otro (condiciones buenas de salud previa), el grupo de personas que no va al hospital no es un buen contrafáctico de las personas que sí van al hospital\nLa diferencia de medias entre los resultados observados de grupos tratados y no tratados a veces se la llama “diferencia asociacional”.\n\nATE: \\(\\mathbb{E}[Y(1) - Y(0)] = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]\\)\nDiferencia asociacional: \\(\\mathbb{E}[(Y|T=1)] - \\mathbb{E}[(Y|T=0)]\\)\n\n\n\n2.2.4 Alcance de la pregunta causal\nAntes de seguir, notemos algunos aspectos sobre el alcance de nuestra pregunta causal. Nos preguntamos si determinado tratamiento genera determinado resultado. Esto es: 1. Queremos encontrar los efectos de ir al hospital sobre la salud, pero no todas las causas del estado de salud. 2. Vamos a comparar los efectos de ser tratado respecto de no ser tratado. 3. Para que tenga sentido la pregunta y podamos identificar un efecto causal, debe haber exposición potencial: todos los individuos deben poder estar potencialmente expuestos a todos los tratamientos, dejando el resto de las circunstancias constantes (sin perder la noción de ceteris paribus). Sólo así hay resultados potenciales para comparar. \\(→\\) Para saber si es posible identificar un efecto causal, podemos preguntarnos si existe un “experimento ideal” que nos permita comparar esos efectos potenciales. Las estrategias de identificación causal tratan de emular ese experimento ideal, de construir un buen contrafáctico.\n¿Cómo podriamos hacer una buena comparación?\nPara hacer una buena comparación, es fundamental el supuesto de independencia:\n\n\\[\\renewcommand{\\indep}{\\perp \\!\\!\\! \\perp} Y_i(0) \\indep T\\] \\[ Y_i(1) \\indep T\\]\n\nEs decir,\n\nla probabilidad de que el individuo \\(i\\) obtenga cierto resultado si se le fuera a administrar el tratamiento no cambian al saber si el tratamiento le fue asignado o no.\nla probabilidad de que el individuo \\(i\\) obtenga cierto resultado si no se le fuera a administrar el tratamiento no cambian al saber si el tratamiento le fue asignado o no.\n\nEn otras palabras esto codifica un balanceo de características: la población que resulta tratada y la que no resulta tratada tienen las mismas características en lo relativo a la obtención de un resultado u otro (un valor u otro de \\(Y_i\\)).\nPodemos reformular el supuesto de independencia como un supuesto de no confusión: asumimos que no hay variables confusoras.\n\n2.2.4.1 Caso experimental\nEn este caso, el diseño nos permite garantizar que no hay variables confusoras. Incluso si antes de aleatorizar el tratamiento hubiera confusores, al aleatorizar hacemos que esas variables dejen de determinar si alguien recibe o no el tratamiento y por lo tanto dejan de ser confusoras.\n\nLa forma en que se garantiza el supuesto de independencia es a través de la asignación aleatoria: dada la población elegible, esta es asignada aleatoriamente a dos grupos: control y tratamiento.\nSi la muestra es lo suficientemente grande, el grupo tratado y el de control serán similares en sus covariables, gracias a la Ley de los Grandes Números (aunque puede haber fluctuaciones). Para tener una mayor confianza, podemos chequear el balanceo en covariables observables luego de realizar la asignación.\n\nEl experimento ideal sería poder hacer una asignación aleatoria en dos etapas: 1. Sortear muestra de elegibles. Asegura validez externa, los elegibles son representativos de la población de interés. 2. Asignar a tratamiento y control. Asegura validez interna. Este es el procedimiento que se realiza tanto en los ensayos aleatorizados controlados (RCTs en inglés), que se realizan por ejemplo para medir el efecto clínico de tratamientos médicos.\n\n\n2.2.4.2 Caso observacional\nEn el caso observacional vamos a asumir en general la existencia de variables confusoras, por las cuales tendremos que controlar. Entonces reemplazamos el supuesto de independencia/no-confusión por el\n\nSupuesto de no-confusión condicional:\n\\[ Y(0) \\indep T \\mid W\\] \\[ Y(1) \\indep T \\mid W\\]\n\ndonde \\(W\\) es algún conjunto de variables observadas por el cual vamos a controlar (por ejemplo, que incluiremos como variables regresoras en una regresión lineal). A este conjunto lo llamamos conjunto de variables de control o conjunto de ajuste.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  },
  {
    "objectID": "capitulo2.html#simulación",
    "href": "capitulo2.html#simulación",
    "title": "1  Modelos Gráficos Probabilísticos y Análisis Causal",
    "section": "2.3 Simulación",
    "text": "2.3 Simulación\nA continuación simularemos unos datos y estimaremos las relaciones entre ellos con el objetivo de identificar el efecto causal.\nLa siguiente simulación nos permitirá:\n\nVer el sesgo que se produce al omitir confusores o variables relevantes\nVer posibles caminos para identificar correctamente el efecto causal: experimentar o controlar por dichos confusores\n\n\n2.3.1 Ejemplo: ¿es fumar perjudicial para la salud?\nSupongamos que queremos ver el efecto del cigarrillo en la salud.\nLo que nos permite la simulación es jugar a que conocemos el verdadero proceso generador de datos, que se compone de las siguientes variables:\nVariable respuesta: - \\(salud_i\\): indicador de salud entre 0 y 100, donde 100 es mejor salud\nCovariables:\n\n\\(edad_i\\): se relaciona negativamente con la salud (empeora la salud al envejecer).\n\\(cigarrillos_i\\): cantidad de cigarrillos fumados por semana. Se relaciona negativamente con la salud (empeora la salud al fumar). En esta población los, jóvenes fuman más.\n\n\\(fumar_i\\): para mantenernos en el marco del tratamiento binario del que venimos hablando (tratados versus no tratados) usaremos esta variable en vez de usar \\(cigarrillos\\). Pero tranquilamente podríamos usar la variable continua (¡pueden probarlo!). Vamos a decir que la persona es “tratada” (fuma mucho) si fuma más que la media. Será la variable de interés, cuyo efecto causal sobre la salud queremos estimar.\n\nProceso generador de datos (“modelo verdadero”): \\[\nsalud_i = 100  - 10  \\; fumar_i - edad_i +  u_i\n\\]\n\\[\ncigarrillos_i = 50 -  0.5  \\; edad_i + \\alpha_i\n\\]\n\\[\nfumar_i = 1 ⇔ cigarrillos_i &gt; E(cigarrillos_i)\n\\]\nCon las siguientes distribuciones:\n\\[ u_i \\sim \\mathcal{N}(0,\\,1)\\ \\] \\[ \\alpha_i \\sim exp(1) \\] \\[ edad_i \\sim \\mathcal{N}(40,\\,10)\\  \\]\nEn este ejemplo de juguete conocemos la verdad respecto del efecto de fumar en la salud. Vemos que la salud depende de los cigarrillos y de la edad, que para aquellos que fuman mucho cae 10 puntos el índice de salud en promedio y que el índice de salud se reduce en 1 punto con cada año que pasa. Notar que \\(u_i\\) es un error aleatorio. La relación entre las covariables y el resultado no es determinística, hay algo de aleatoriedad de persona a persona.\nEn esta simulación vamos a generar algunos datos, que es con lo que nos enfrentaremos en la realidad: tendremos unas cuantas mediciones del índice de salud, de la edad y de los cigarrillos consumidos para cada persona. Veremos si a partir de esos datos podemos recuperar el efecto causal de fumar sobre el índice de salud, que sabemos que es -10.\nSimularemos una población de 10000 individuos:\nnp.random.seed(9)\ndef simular_poblacion(N = 10000):\n    # variables\n    edad = np.random.normal(40, 10, size = N)\n    cigarrillos = 50 -0.5 * edad + np.random.exponential(scale = 1, size = N)\n    fumar = np.array([1 if i &gt; np.mean(cigarrillos) else 0 for i in cigarrillos])\n    salud = 100 - 10 * fumar  - edad + np.random.normal(size = N)\n\n    data = pd.DataFrame(np.array([salud, edad, cigarrillos, fumar]).transpose())\n    data.columns = ['salud', 'edad', 'cigarrillos', 'fumar']\n    return data\n\ndata = simular_poblacion(N = 10000)\ndata.head()\n# Graficamos las series para tener una idea de la distribución de los datos\nfig, axs = plt.subplots(2, 3, figsize=(10, 10))\nfig.tight_layout()\n\nsns.histplot(data=data, x=\"edad\", kde=True, ax=axs[0, 0])\nsns.histplot(data=data, x=\"fumar\", kde=False, ax=axs[0, 1])\nsns.histplot(data=data, x=\"salud\", kde=True, ax=axs[0, 2])\nsns.scatterplot(data=data, x=\"salud\", y=\"edad\", hue = \"fumar\",ax=axs[1, 0])\nsns.scatterplot(data=data, x=\"salud\", y=\"fumar\", hue = \"fumar\", ax=axs[1, 1])\nsns.scatterplot(data=data, x=\"edad\", y=\"fumar\", hue = \"fumar\", ax=axs[1, 2])\n\nplt.show()\nA simple vista, podemos ver 3 patrones: - Los fumadores suelen ser jóvenes. - Los jóvenes tienen mejor salud. - Los fumadores tienen mejor salud.\nAhora que ya hemos hecho un análisis exploratorio, vamos a modelizar los datos:\n\nModelo “mal especificado”: Se nos ocurre estimar una regresión lineal sin incluir edad como covariable, es decir: \\[salud_i = \\beta_0 + \\beta_1  \\; fumar_i + u_i\\]\n\nX = data[['fumar']]\ny = data['salud']\n\nreg = LinearRegression().fit(X, y)\nprint(f\"Valor estimado de beta_1 (efecto de fumar): {reg.coef_[0]}\")\nCon nuestro modelo no identificamos bien el efecto causal: el \\(\\beta_1\\) estimado es 5,5. Pareciera que fumar es bueno para la salud y como conocemos el modelo verdadero, sabemos que no es así. ¿Cómo se explica que el efecto de fumar en la salud parezca positivo?\n\nModelo “bien especificado”. Se nos ocurre estimar una regresión lineal incluyendo edad como covariable. Es decir, el siguiente modelo: \\[salud_i = \\beta_0 + \\beta_1  \\; fumar_i + \\beta_2  \\; edad_i +  u_i\\]\n\nX = data[['fumar', 'edad']]\ny = data['salud']\n\nreg = LinearRegression().fit(X, y)\nprint(f\"Valor estimado de beta_1 (efecto de fumar)  : {reg.coef_[0]}\")\nprint(f\"Valor estimado de beta_2 (efecto de la edad): {reg.coef_[1]}\")\nEn este caso hemos obtenido una estimación del efecto de fumar muy acertada. Lo que estaba ocurriendo era que la edad era una variable de confusión y no podiamos estimar el efecto de fumar. Ahora que hemos controlado por la edad, hemos capturado correctamente el efecto de fumar.\nSupongamos que no contamos con la variable edad. Sin embargo, podemos diseñar un experimento: distribuir aleatoriamente a un grupo de 10000 personas entre fumadores y no fumadores.\n# Asignamos aleatoriamente quién será fumador y quién no\ndata[\"fumar_exp\"] = np.round(np.random.binomial(1, 0.5, len(data)))\n\n# Dado el consumo de cigarrillos, calculamos el índice de salud\ndata[\"salud_exp\"] = 100 - 10 * data.fumar_exp  - data.edad + np.random.normal(size = len(data))\n\n# Graficamos\nsns.histplot(data=data, x=\"edad\",  hue=\"fumar_exp\").set_title(\"Distribución de la edad por fumar\")\nComo podemos observar, al elegir aleatoriamente a los individuos entre fumadores y no fumadores, ambos grupos poseen unas edades similares, por lo que ahora, la edad no tendrá correlación con la variable fumar.\nX = data[['fumar_exp']]\ny = data['salud_exp']\n\nreg = LinearRegression().fit(X, y)\nprint(f\"Valor estimado de beta_1 (efecto de fumar_exp)  : {reg.coef_[0]}\")\nVolvimos a recuperar el efecto causal usando unicamente la variable fumar en nuestro modelo, ya que pudimos controlar el efecto de la edad.\nLo que nos ha ocurrido en el experimento cuando hemos obtenido valores de \\(\\beta_1\\) tan opuestos, se llama paradoja de Simpson, una de las más conoidas en el mundo causal.\n\n\n2.3.2 Paradoja de Simpson\nLa Paradoja de Simpson es “una paradoja en la cual una tendencia que aparece en varios grupos de datos desaparece cuando estos grupos se combinan y en su lugar aparece la tendencia contraria para los datos agregados”. Esta paradoja “desaparece cuando se analizan las relaciones causales presentes”. O dicho de otra forma: cuando la asociación entre dos variables cambia completamente cuando se tiene en cuenta (se controla) el efecto de una tercera variable que no se había tenido en cuenta.\nVeamos un caso real: la Universidad de California, Berkeley, fue demandada por un caso de discriminación contra las mujeres.\n\n\n\n\nSolicitudes\nAdmisiones\n\n\n\n\nHombres\n8442\n44%\n\n\nMujeres\n4321\n35%\n\n\n\ncon estos datos, se acusó a la universidad de favorecer el acceso a hombres frente a mujeres, ya que se observaba una diferencia de casi un 10% en los porcentajes de admisión de ambos grupos. Pero con los mismos datos de admisiones, solo que añadiendo la variable Departamento, se podía apreciar algo totalmente distinto:\n\n\n\n\n\n\n\n\n\n\nDepartamento\nSolicitudes de Hombres\nAdmisiones de Hombres (%)\nSolicitudes de Mujeres\nAdmisiones de Mujeres (%)\n\n\n\n\nA\n685\n62%\n108\n82%\n\n\nB\n560\n63%\n25\n68%\n\n\nC\n325\n37%\n593\n34%\n\n\nD\n417\n33%\n375\n35%\n\n\nE\n191\n28%\n393\n24%\n\n\nF\n272\n6%\n341\n7%\n\n\n\nLos datos en una y otra tabla son exactamente los mismos, provienen de la misma fuente. Y sin embargo, dependiendo de cómo dividas esos datos, pueden sacarse conclusiones completamente opuestas. De ahí lo importantante que es saber qué variables pueden afectar en nuestro análisis, en este caso, el tener en cuenta el tipo de solicitudes.\nJavier Álvarez Liébana tiene un gran hilo en X, donde habla sobre la paradoja de Simpson.\nPor cosas como esta, es por lo que se dice que las estadísticas, como las armas, las carga el diablo.\n\n2.3.2.1 Conclusiones de la simulación\n\nLa edad es una variable confusora: es relevante para el resultado y además está correlacionada con la variable de tratamiento. Si la omitimos, no podemos identificar correctamente el efecto causal de fumar en la salud. Aparece un sesgo y pareciera que fumar se asocia a tener una mayor salud. Se “confunde” el efecto propio de fumar en la salud con el hecho de que los fumadores en general son jóvenes y los jóvenes tienen mejor salud. pero no podemos saber qué parte de la diferencia en la salud promedio de fumadores y no fumadores es efectivamente atribuible al tratamiento (a fumar) y qué parte es atribuible al confusor (a que los fumadores son jóvenes).\n\n\nLas variables confusoras son aquellas que correlacionan tanto con el tratamiento como con el resultado. Esto hace que los no tratados no sean un buen contrafáctico para los tratados. Porque si los tratados tienen una característica más allá del tratamiento que los diferencia de los no tratados, y esa característica puede influir sobre la variable de resultado, no tenemos forma de distinguir que es el tratamiento y no esta otra variable la causa de los resultados diferentes que observemos. Si no controlamos por ella, la confundiremos con el tratamiento.\n\n\nAl experimentar, rompemos la relación de fumar con la edad. Los tratados y no tratados pasan a tener edades que en promedio son similares entre sí. Si ninguno fumara, en promedio los tratados y los no tratados tendrían la misma salud: el resultado potencial de no recibir tratamiento (de no fumar) es el mismo, se cumple el supuesto de independencia.\nControlar por la edad permite separar los efectos parciales de fumar y de la edad en la salud. Le “quita” a la variable \\(fumar\\) la parte que afecta a la salud a través de la edad. O, lo que es lo mismo, permite comparar fumadores versus no fumadores entre grupos de la misma edad. Condicional en la edad, el resultado potencial de recibir tratamiento (de no fumar) es el mismo, se cumple el supuesto de independencia.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Modelos Gráficos Probabilísticos y Análisis Causal</span>"
    ]
  }
]